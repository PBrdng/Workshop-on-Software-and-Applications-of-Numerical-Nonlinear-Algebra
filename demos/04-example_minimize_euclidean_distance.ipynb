{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>\n",
    "\n",
    "# Example: minimize the euclidean distance to variety\n",
    "\n",
    "In this fourth notebook we want to apply what we have learned so far in an example.\n",
    "\n",
    "Consider the distance from a point $u \\in \\mathbb{R}^n$ to the variety $X=V(f_1,\\ldots,f_m)$.\n",
    "We want to solve the following optimization problem:\n",
    "\n",
    "<div style=\"text-align:center;margin-top:20px;\"><em>What is the nearest point on $X$ to $u$ with respect to the euclidean distance?</em></div>\n",
    "\n",
    "Let us illustrate this with an example. Consider the polynomial\n",
    "$$f(x,y) = (x^4 + y^4 - 1)(x^2 + y^2 - 2)  + x^5y$$\n",
    "and the point $u_0 = [-0.32, -0.1]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using HomotopyContinuation\n",
    "@var x y\n",
    "f = (x^4 + y^4 - 1)*(x^2 + y^2 - 2) + x^5*y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can formulate our problem as the constrained optimization problem\n",
    "\n",
    "$$\\min\\; (x + 0.32)^2 + (y+0.1)^2 \\quad \\text{ s.t.} \\quad  f(x,y) = 0 $$\n",
    "\n",
    "This a non-linear, non-convex minimization problem and therefore it can have multiple local minima as well as local maxima and saddle points. If we approach this problem with a simple gradient descent algorithm starting from a random point we might get as a result a *local* minimum *but* we do **not** know whether this is the global minimum!\n",
    "\n",
    "In order to make sure that we find the *optimal* solution we will compute **all** critical points of this optimization problem.\n",
    "If we count the number of critical points over the *complex numbers* then this number will *almost always* be the same. It is called the *Euclidean Distance degree* of $X=V(f)$.\n",
    "    \n",
    "<hr style=\"border:1px solid gray\"> </hr>\n",
    "\n",
    "# Solving the critical equations\n",
    "\n",
    "Let us derive the equations for the critical equations in general in order to apply them afterwards to our example.\n",
    "For a given $u \\in \\mathbb{R}^n$ we want to solve the problem:\n",
    "\n",
    "$$\\min ||(x,y)-u||_2^2=:d_u(x) \\quad \\text{subject to} \\quad f(x,y) = 0.$$\n",
    "\n",
    "Considering the geometry of the problem  you can see that a point $z^{*} =(x^*,y^*)$ is a critical point of the distance function\n",
    "if and only if\n",
    "$z^{*} - u$ is orthogonal to the tangent space of $X$ at $z^{*} $; that is,\n",
    "$ (z^{*} - u) \\perp T_{z^*}X \\,.$\n",
    "\n",
    "Let us denote by $\\nabla f(x,y)$ the gradient of $f$ at $(x,y)$. The gradient spans the normal space of $V=\\{f(x,y)=0\\}$ at $(x,y)$ and so the critical points satisfy the Langrange multiplier equations\n",
    "$$\\begin{array}{rl}(x,y)-u &= \\lambda \\nabla f(x,y) \\\\ f(x,y) &= 0 \\\\ \\lambda &\\in \\mathbb{R}^m \\end{array}$$\n",
    "\n",
    "Let's definie the critical equations in Julia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@var u[1:2] λ\n",
    "# define the jacobian of F\n",
    "∇f = differentiate(f, [x; y])\n",
    "# J' defines the transpose of J\n",
    "C = [[x,y] - u - λ .* ∇f; f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define the point $u_0 =[-0.32, -0.1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u₀ = [-0.32, -0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to make the substitution $u \\Rightarrow u_0$ before we can solve the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_u₀ = [subs(c, u => u₀) for c in C]\n",
    "res = solve(C_u₀) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the real points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get all real solutions\n",
    "real_sols = real_solutions(res)\n",
    "# We have to remove our artifical variable λ₁\n",
    "ed_points = map(p -> p[1:2], real_sols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal solution is found as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "dist, idx = findmin([norm(x - u₀) for x in ed_points])\n",
    "p_optimal = ed_points[idx]\n",
    "println(\"Optimal solution: \", p_optimal, \" with distance \", sqrt(dist), \" to u₀\")"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
